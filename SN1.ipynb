{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKsEWvzhhPMzIJ4FGtYodk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/domingues100/IEEE---Water_Level/blob/main/SN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORTS**"
      ],
      "metadata": {
        "id": "d759AuWAySSQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SlSiCHa4LVD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet50V2, ResNet101V2\n",
        "#from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "ID6lCed44M5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Side Functions**"
      ],
      "metadata": {
        "id": "e6bkzgZ0DYuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idg = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    imagem = image.load_img(image_path, target_size=(224, 224))\n",
        "    imagem_array = image.img_to_array(imagem)\n",
        "    imagem_array = np.expand_dims(imagem_array, axis=0)\n",
        "    imagem_array = idg.flow(imagem_array, batch_size=1)[0]\n",
        "    return imagem_array\n",
        "\n",
        "def generate_feature_vector(img_path):\n",
        "    img = load_and_preprocess_image(img_path)\n",
        "    features = model.predict(img)\n",
        "    feature_vector = np.array(features.flatten())\n",
        "    return feature_vector\n",
        "\n",
        "def list_features_classes(images_df, path):\n",
        "    feature_vectors = []\n",
        "    class_name = []\n",
        "\n",
        "    for index, row in images_df.iterrows():\n",
        "        image = row['id']\n",
        "        classe = row['label']\n",
        "\n",
        "        feature_vector = generate_feature_vector(os.path.join(path, image))\n",
        "        class_name.append(classe)\n",
        "        feature_vectors.append(feature_vector)\n",
        "\n",
        "    return class_name, feature_vectors\n",
        "\n",
        "def create_csv(classe, feature, feature_csv_name):\n",
        "    vetores_path = f'/content/drive/MyDrive/Transaciones/SN1/Teste 2 - 5 imagem/{feature_csv_name}'\n",
        "    data = {'Classe': classe, 'Feature_vector': feature}\n",
        "    faces_df = pd.DataFrame(data)\n",
        "    faces_df.to_csv(vetores_path, index=False)\n",
        "\n",
        "    return vetores_path\n",
        "\n",
        "def distancia_euclidiana(vec1, vec2):\n",
        "    \"\"\"\n",
        "    Passando 2 vetores, obt√©m-se a distancia euclidiana entre eles\n",
        "    vec1 = feature_vector 1\n",
        "    vec2 = feature_vector 2\n",
        "    \"\"\"\n",
        "    return np.linalg.norm(vec1 - vec2)\n",
        "\n",
        "def comparar_features(new_feature_vector, features_csv):\n",
        "    df = pd.read_csv(features_csv)\n",
        "\n",
        "    df['Feature_vector'] = df['Feature_vector'].apply(lambda x: np.fromstring(x[1:-1], sep=\" \"))\n",
        "\n",
        "    label = None\n",
        "    distancia_minima = float('inf')\n",
        "\n",
        "    for index, linha in df.iterrows():\n",
        "      distancia = distancia_euclidiana(new_feature_vector, np.array(linha['Feature_vector']))\n",
        "      if distancia < distancia_minima:\n",
        "          distancia_minima = distancia\n",
        "          label = linha['Classe']\n",
        "\n",
        "    return label\n",
        "\n",
        "\n",
        "def generate_metrics(results, true_label):\n",
        "    accuracy = accuracy_score(true_label, results)\n",
        "    precision = precision_score(true_label, results, average='macro')\n",
        "    recall = recall_score(true_label, results, average='macro')\n",
        "    f1 = f1_score(true_label, results, average='macro')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "\n",
        "def generate_results(teste_df, vetores):\n",
        "    results = []\n",
        "    true_label = []\n",
        "    for index, row in teste_df.iterrows():\n",
        "        image_path = os.path.join(path, row['id'])\n",
        "        classe = row['label']\n",
        "\n",
        "        new_feature_vector = generate_feature_vector(image_path)\n",
        "        label = comparar_features(new_feature_vector, vetores)\n",
        "\n",
        "        results.append(label)\n",
        "        true_label.append(classe)\n",
        "\n",
        "    accuracy, precision, recall, f1 = generate_metrics(results, true_label)\n",
        "    return results, true_label, accuracy, precision, recall, f1\n",
        "\n",
        "def generate_random_samples(csv):\n",
        "    df = pd.read_csv(csv)\n",
        "    insert_df = df.groupby('label').apply(lambda x: x.sample(n=5))\n",
        "    return insert_df"
      ],
      "metadata": {
        "id": "4oZlYZKq4TGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TESTS**"
      ],
      "metadata": {
        "id": "zHEWYOxWFBIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(threshold=np.inf)"
      ],
      "metadata": {
        "id": "Q2ADnFbCFD4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TESTE 4**"
      ],
      "metadata": {
        "id": "WkAUErbP4Wsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image path and load csv for feature extraction\n",
        "#load weights from the first classification model. In this, the model trained before will be used\n",
        "#this allows to use the same folders, and same weights.\n",
        "dir = #path were the classification stuf is saved\n",
        "path = #image path\n",
        "new_save_path = #new path to save test results\n",
        "for i in range(1, 6):\n",
        "  acc1 = []\n",
        "  prec1 = []\n",
        "  rec1 = []\n",
        "  f11 = []\n",
        "\n",
        "  model = load_model(f'{dir}/model{i}.h5')\n",
        "  model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "\n",
        "  insert_df = pd.read_csv(f'{dir}/training_data{i}.csv')\n",
        "  test_df = pd.read_csv(f'{dir}/validation_data{i}.csv')\n",
        "\n",
        "  #create features csv\n",
        "  classe, feature = list_features_classes(insert_df, path)\n",
        "  vetores_path = create_csv(classe, feature, feature_csv_name = f\"vetores_teste{i}.csv\")\n",
        "\n",
        "  results, true_label, accuracy, precision, recall, f1 = generate_results(test_df, vetores_path)\n",
        "\n",
        "  acc1.append(accuracy)\n",
        "  prec1.append(precision)\n",
        "  rec1.append(recall)\n",
        "  f11.append(f1)\n",
        "\n",
        "  df = pd.DataFrame({'results': results, 'true_label': true_label})\n",
        "  df.to_csv(f'{new_save_path}/df{i}.csv', index=False)\n",
        "\n",
        "acc1 = [np.array(acc1).mean()]\n",
        "prec1 = [np.array(prec1).mean()]\n",
        "rec1 = [np.array(rec1).mean()]\n",
        "f11 = [np.array(f11).mean()]\n",
        "\n",
        "df = pd.DataFrame({'acc_mean': acc1, 'prec_mean': prec1, 'rec_mean': rec1, 'f1_mean': f11})\n",
        "df.to_csv(f'{new_save_path}/df_mean.csv', index=False)"
      ],
      "metadata": {
        "id": "UG16sCJU4Y6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TEST 1, 2, 3**"
      ],
      "metadata": {
        "id": "W9IIaC-l4bIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image path and load csv for feature extraction\n",
        "#load weights from the first classification model. In this, the model trained before will be used\n",
        "#this allows to use the same folders, and same weights.\n",
        "dir = #path were the classification stuf is saved\n",
        "path = #image path\n",
        "new_save_path = #new path to save test results\n",
        "test_number = #put the number of the test to save results in another folder\n",
        "\n",
        "\n",
        "#you need to run this 3 times, each time for a different test, remember to change the test number\n",
        "#you need to go on generate_random_samples() and change n in x.sample(n=5), for test1 n=1, test2 n=3, test 3 n=5\n",
        "for i in range(1, 6):\n",
        "  acc1 = []\n",
        "  prec1 = []\n",
        "  rec1 = []\n",
        "  f11 = []\n",
        "  results1 = []\n",
        "  true_label1 = []\n",
        "\n",
        "  for j in range(20):\n",
        "    model = load_model(f'{dir}/model{i}.h5')\n",
        "    model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "\n",
        "    insert_df = generate_random_samples(f'{dir}/training_data{i}.csv')\n",
        "    test_df = pd.read_csv(f'{dir}/validation_data{i}.csv')\n",
        "\n",
        "    #create features csv\n",
        "    classe, feature = list_features_classes(insert_df, path)\n",
        "    vetores_path = create_csv(classe, feature, feature_csv_name = f\"vetores_teste{i}.csv\")\n",
        "\n",
        "    results, true_label, accuracy, precision, recall, f1 = generate_results(test_df, vetores_path)\n",
        "\n",
        "    acc1.append(accuracy)\n",
        "    prec1.append(precision)\n",
        "    rec1.append(recall)\n",
        "    f11.append(f1)\n",
        "    results1.append(results)\n",
        "    true_label1.append(true_label)\n",
        "\n",
        "  df = pd.DataFrame({'results': results1, 'true_label': true_label1})\n",
        "  df.to_csv(f'{new_save_path}/test{test_number}/df{i}.csv', index=False)\n",
        "\n",
        "acc1 = [np.array(acc1).mean()]\n",
        "prec1 = [np.array(prec1).mean()]\n",
        "rec1 = [np.array(rec1).mean()]\n",
        "f11 = [np.array(f11).mean()]\n",
        "\n",
        "df = pd.DataFrame({'acc_mean': acc1, 'prec_mean': prec1, 'rec_mean': rec1, 'f1_mean': f11})\n",
        "df.to_csv(f'{new_save_path}/test{test_number}/df_mean.csv', index=False)"
      ],
      "metadata": {
        "id": "6B971QhN4ceI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}