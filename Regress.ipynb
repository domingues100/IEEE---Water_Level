{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/domingues100/IEEE---Water_Level/blob/main/Regress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5savH5UHnplo"
      },
      "source": [
        "\n",
        "\n",
        "# **Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLdsXvwzniPF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcjHTZ67nueW"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBYMRa8wohPR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from shutil import copy2\n",
        "import csv\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import gc\n",
        "import statistics\n",
        "from keras.layers import Lambda\n",
        "import joblib\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ipxcrFCbd5y"
      },
      "source": [
        "# **KFOLD**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSYJxkSDt5xT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/IC_Machine_Learning/instances_default.csv')\n",
        "\n",
        "for ind in train_data.index:\n",
        "  train_data.loc[ind, 'label'] = train_data.loc[ind, 'label'] - 3\n",
        "\n",
        "Y = train_data[['label']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvKNAE3hgePW"
      },
      "outputs": [],
      "source": [
        "num_epochs = 100\n",
        "\n",
        "idg = ImageDataGenerator(width_shift_range=0.3,\n",
        "                         height_shift_range=0.3,\n",
        "                         rotation_range=0.4,\n",
        "                         zoom_range=0.4,\n",
        "                         fill_mode='nearest',\n",
        "                         horizontal_flip = True,\n",
        "                         rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YK9Up3WvC0S"
      },
      "outputs": [],
      "source": [
        "save_dir = #save_path\n",
        "image_dir = #img dir ->remember to resize to 224x224\n",
        "\n",
        "folder_old_path = #path to the folds used in class\n",
        "\n",
        "\n",
        "fold_var = 1\n",
        "n = Y.size\n",
        "\n",
        "\n",
        "for i in range(1,6):\n",
        "  training_data = pd.read_csv(f\"{folder_old_path}/training_data{i}.csv\")\n",
        "  validation_data = pd.read_csv(f\"{folder_old_path}o/validation_data{i}.csv\")\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(training_data[\"label\"].to_numpy().reshape([-1,1]))\n",
        "\n",
        "  validation_data[\"normalizado\"] = scaler.transform(validation_data[\"label\"].to_numpy().reshape([-1,1]))\n",
        "  training_data[\"normalizado\"] = scaler.transform(training_data[\"label\"].to_numpy().reshape([-1,1]))\n",
        "\n",
        "  #data generators - training and validating\n",
        "  train_data_generator = idg.flow_from_dataframe(training_data, directory = image_dir,\n",
        "\t\t\t\t\t\t             x_col = \"id\", y_col = \"normalizado\",\n",
        "\t\t\t\t\t\t             class_mode = \"raw\", shuffle = True, batch_size=32)\n",
        "\n",
        "  valid_data_generator = idg.flow_from_dataframe(validation_data, directory = image_dir,\n",
        "\t\t\t\t\t\t\t           x_col = \"id\", y_col = \"normalizado\",\n",
        "\t\t\t\t\t\t\t           class_mode = \"raw\", shuffle = False, batch_size=32)\n",
        "\n",
        "\n",
        "#Model\n",
        "  base_model = keras.applications.ResNet50V2(\n",
        "               include_top=False,\n",
        "               weights='imagenet',\n",
        "               input_shape=(224, 224, 3))\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "\n",
        "  model = keras.Sequential([\n",
        "\n",
        "    base_model,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dense(256, activation ='relu'),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Dense(1, activation='linear')\n",
        "  ])\n",
        "\n",
        "  # Optimizer\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "\t# Compile Model\n",
        "  model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy', 'mse'])\n",
        "\n",
        "\t# Fit Model\n",
        "  history = model.fit(train_data_generator, epochs=num_epochs, validation_data=valid_data_generator) #validation_data=valid_data_generator\n",
        "\n",
        "  # Save Model\n",
        "  tf.keras.backend.clear_session()\n",
        "  model.save(save_dir + f\"/model{fold_var}.h5\")\n",
        "  joblib.dump(scaler, save_dir +\"/scaler\"+str(fold_var)) #saves the standart scaler to use for predictions\n",
        "\n",
        "  fold_var += 1\n",
        "  gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puHdnyVbB9Tb"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukeNCrE_kZJ0"
      },
      "source": [
        "Necessary run diretory cells and idg before\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4lO63lBApM9"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "base_model = keras.applications.ResNet50V2(\n",
        "               include_top=False,\n",
        "               weights='imagenet',\n",
        "               input_shape=(224, 224, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "#   # Model Def\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    keras.layers.GlobalAveragePooling2D(),\n",
        "    keras.layers.Dense(256, activation ='relu'),\n",
        "    keras.layers.Dropout(0.4),\n",
        "    keras.layers.Dense(1, activation='linear')\n",
        "  ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXsJPZ4vABT2"
      },
      "outputs": [],
      "source": [
        "save_dir =  #save_path\n",
        "image_dir = #image path ->resized to 224\n",
        "folder_old_path = #path to the folds used in class\n",
        "\n",
        "var = 1\n",
        "accuracy = []\n",
        "k=0\n",
        "\n",
        "\n",
        "for k in range(5):\n",
        "  validation_data = pd.read_csv(f\"{folder_old_path}/validation_data{k+1}.csv\")\n",
        "  scaler =joblib.load(save_dir +\"/scaler\"+str(k+1))\n",
        "\n",
        "  valid_data_generator = idg.flow_from_dataframe(validation_data, directory = image_dir,\n",
        "\t\t\t\t\t\t\t           x_col = \"id\", y_col = \"label\",\n",
        "\t\t\t\t\t\t\t           class_mode = \"raw\", shuffle = False, batch_size=32)\n",
        "\n",
        "\n",
        "\n",
        "  model.load_weights(f\"{save_dir}/model{k+1}.h5\")\n",
        "  pred = model.predict(valid_data_generator)\n",
        "  pred = scaler.inverse_transform(pred)\n",
        "  pred = np.squeeze(pred)\n",
        "\n",
        "  for itens in validation_data:\n",
        "    val_data = validation_data[\"label\"] .values.tolist()\n",
        "\n",
        "\n",
        "  val_data = list(map(int, val_data))\n",
        "\n",
        "  k += 1\n",
        "\n",
        "  dados = {\"predicted_desnormalizado\": pred, \"labels\": val_data}\n",
        "  df = pd.DataFrame(dados)\n",
        "  df.to_csv(save_dir+f\"/df{k}.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5savH5UHnplo",
        "vcjHTZ67nueW"
      ],
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}